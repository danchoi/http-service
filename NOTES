


Maybe the HTTP service can be used by IW for API requests.

The HTTP service can throttle to keep things under a rate limit, and
also track the requests over time.


Resources:
  urls
    url
  requests
    request_id
    url
    redirected to
    response
    time elapsed
    content_type
  crawl:
    a collection of requests


psql http-service -c 'select url, response_code, content_type, error from requests'

psql http-service -c 'select crawl_id, url, response_code, content_type, latency, error from requests'



[choi world~/p]$ curl http://localhost:9292/crawl/1 | parsejson

{"state"=>"pending",
 "message"=>"Your request is still processing",
 "link"=>{"rel"=>"self", "href"=>"http://localhost:9292/crawl/20"}}

{"state"=>"done",
 "message"=>"Your request has been processed",
 "link"=>{"rel"=>"self", "href"=>"http://localhost:9292/crawl/19"},
 "links"=>
  [{"rel"=>"processed_url",
    "href"=>"http://fulltextrssfeed.com/gonedigital.net/feed"},
   {"rel"=>"processed_url",
    "href"=>"http://fulltextrssfeed.com/www.telegraph.co.uk/news/rss"},
   {"rel"=>"processed_url",
    "href"=>
     "http://fulltextrssfeed.com/www.basingstokegazette.co.uk/news/rss"},
   {"rel"=>"processed_url",
    "href"=>"http://fulltextrssfeed.com/www.thesquareball.net/feed"},
   {"rel"=>"processed_url",
    "href"=>"http://fulltextrssfeed.com/www.badscience.net/feed"},
   {"rel"=>"processed_url",
    "href"=>
     "http://fulltextrssfeed.com/www.economist.com/feeds/print-sections/76/britain.xml"},
   {"rel"=>"processed_url",
    "href"=>
     "http://fulltextrssfeed.com/www.basingstokegazette.co.uk/business/rss"},
   {"rel"=>"processed_url", "href"=>"http://nosoftskills.com/feed"},
   {"rel"=>"processed_url",
    "href"=>
     "http://feedsanitizer.appspot.com/sanitize?url=http%3A%2F%2Fsimu.rtwblog.de%2Ffeed%2F&format=rss"},
   {"rel"=>"processed_url",
    "href"=>"http://fulltextrssfeed.com/blog.independent.org/feed"},
   {"rel"=>"processed_url", "href"=>"http://kindlefeeder.com/fail"},
   {"rel"=>"processed_url", "href"=>"http://kindlefeeders.com/fail"}]}


{"state"=>"done",
 "message"=>"Your request has been processed",
 "link"=>{"rel"=>"self", "href"=>"http://localhost:9292/crawl/1"},
 "links"=>
  [{"rel"=>"processed_url", "href"=>"http://localhost:9292/url/4"},
   {"rel"=>"processed_url", "href"=>"http://localhost:9292/url/2"},
   {"rel"=>"processed_url", "href"=>"http://localhost:9292/url/1"},
   {"rel"=>"processed_url", "href"=>"http://localhost:9292/url/8"},
   {"rel"=>"processed_url", "href"=>"http://localhost:9292/url/6"},
   {"rel"=>"processed_url", "href"=>"http://localhost:9292/url/5"},
   {"rel"=>"processed_url", "href"=>"http://localhost:9292/url/3"},
   {"rel"=>"processed_url", "href"=>"http://localhost:9292/url/9"},
   {"rel"=>"processed_url", "href"=>"http://localhost:9292/url/10"},
   {"rel"=>"processed_url", "href"=>"http://localhost:9292/url/7"},
   {"rel"=>"processed_url", "href"=>"http://localhost:9292/url/12"},
   {"rel"=>"processed_url", "href"=>"http://localhost:9292/url/11"}]}

# included failed urls?



  759  ./recreate.sh
  760  ruby test/json.rb
  762  ruby -Ilib lib/http_service/crawl.rb 1  # process crawl
  765  curl http://localhost:9292/crawl/1 | parsejson >> NOTES
 


[choi world~]$ curl -s http://localhost:9292/url/10 | parsejson
{"url"=>
  "http://feedsanitizer.appspot.com/sanitize?url=http%3A%2F%2Fsimu.rtwblog.de%2Ffeed%2F&format=rss",
 "response_code"=>200,
 "redirect"=>nil,
 "content_type"=>"application/rss+xml",
 "headers"=>
  "HTTP/1.1 200 OK\r\nContent-Type: application/rss+xml\r\nVary: Accept-Encoding\r\nDate: Fri, 23 Mar 2012 03:04:52 GMT\r\nServer: Google Frontend\r\nCache-Control: private\r\nTransfer-Encoding: chunked\r\n\r\n",
 "created"=>"2012-03-22 23:04:52 -0400",
 "error"=>nil,
 "body_length"=>8139}


# To get the payload:

[choi world~]$ curl -s http://localhost:9292/url/10/body 



